/*
 * ATTENTION: The "eval" devtool has been used (maybe by default in mode: "development").
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
/******/ (() => { // webpackBootstrap
/******/ 	"use strict";
/******/ 	var __webpack_modules__ = ({

/***/ "./example/Example.js":
/*!****************************!*\
  !*** ./example/Example.js ***!
  \****************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

eval("\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nconst Geometry_1 = __webpack_require__(/*! ../src/Geometry */ \"./src/Geometry.js\");\nconst Material_1 = __webpack_require__(/*! ../src/Material */ \"./src/Material.js\");\nconst Renderer_1 = __webpack_require__(/*! ../src/Renderer */ \"./src/Renderer.js\");\nconst ITexture_1 = __webpack_require__(/*! ../src/ITexture */ \"./src/ITexture.js\");\nconst Rectangle_1 = __webpack_require__(/*! ./meshes/Rectangle */ \"./example/meshes/Rectangle.js\");\nconst Scene_1 = __webpack_require__(/*! ../src/Scene */ \"./src/Scene.js\");\nconst Mesh_1 = __webpack_require__(/*! ../src/Mesh */ \"./src/Mesh.js\");\nconst raymarchShader_1 = __webpack_require__(/*! ./shaders/wglsl/raymarchShader */ \"./example/shaders/wglsl/raymarchShader.js\");\ndocument.addEventListener(\"DOMContentLoaded\", () => __awaiter(void 0, void 0, void 0, function* () {\n    const canvas = document.querySelector('canvas');\n    const renderer = new Renderer_1.Renderer(canvas);\n    const device = yield renderer.getDevice();\n    const scene = new Scene_1.Scene(\"myScene\", device, canvas);\n    const material = new Material_1.Material(device, raymarchShader_1.raymarchShader);\n    const geometry = new Geometry_1.Geometry(device, Rectangle_1.rectGeometry);\n    const textures = [\n        {\n            key: \"iChannel0\",\n            source: \"assets/video.webm\", // ms \n            type: ITexture_1.TextureType.video,\n        },\n        {\n            key: \"iChannel1\",\n            source: \"assets/channel0.jpg\",\n            type: ITexture_1.TextureType.image\n        },\n    ];\n    //  const samplers: Array<GPUSamplerDescriptor> = [{\n    //   addressModeU: 'repeat',\n    //   addressModeV: 'repeat',\n    //   magFilter: 'linear',\n    //   minFilter: 'nearest' // linear sampler, binding 2, as uniforms is bound to 1    \n    // }];\n    const mesh = new Mesh_1.Mesh(device, geometry, material, [textures[0], textures[1]]);\n    yield scene.addAssets(textures);\n    scene.addMesh(\"myMesh\", mesh);\n    yield renderer.addScene(scene);\n    renderer.start(0);\n}));\n\n\n//# sourceURL=webpack://demolishedwebgpu/./example/Example.js?");

/***/ }),

/***/ "./example/meshes/Rectangle.js":
/*!*************************************!*\
  !*** ./example/meshes/Rectangle.js ***!
  \*************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.rectGeometry = void 0;\nconst Geometry_1 = __webpack_require__(/*! ../../src/Geometry */ \"./src/Geometry.js\");\nexports.rectGeometry = {\n    verticesType: Geometry_1.VERTEXType.xyzwrgba,\n    vertices: new Float32Array([\n        -1, 1, 0, 1, 0, 1, 1, 1,\n        -1, -1, 0, 1, 0, 1, 1, 1,\n        1, -1, 0, 1, 0, 1, 1, 1,\n        -1, 1, 0, 1, 0, 1, 1, 1,\n        1, -1, 0, 1, 0, 1, 1, 1,\n        1, 1, 0, 1, 0, 1, 1, 1,\n    ]),\n    indicies: new Uint16Array([0, 1, 2, 3, 4, 5,]),\n};\n\n\n//# sourceURL=webpack://demolishedwebgpu/./example/meshes/Rectangle.js?");

/***/ }),

/***/ "./example/shaders/wglsl/raymarchShader.js":
/*!*************************************************!*\
  !*** ./example/shaders/wglsl/raymarchShader.js ***!
  \*************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.raymarchShader = void 0;\nconst Material_1 = __webpack_require__(/*! ../../../src/Material */ \"./src/Material.js\");\nexports.raymarchShader = {\n    vertex: Material_1.defaultWglslVertex,\n    fragment: /* glsl */ `\r\n    \r\n    struct Uniforms {\r\n      resolution: vec3<f32>,\r\n      time: f32\r\n    };\r\n\r\n    @group(0) @binding(0) var<uniform> uniforms: Uniforms;\r\n\r\n    struct VertexOutput {\r\n        @builtin(position) pos: vec4<f32>,\r\n        @location(0) uv: vec2<f32>\r\n      };  \r\n      \r\n    var<private> orb: vec4<f32>;\r\n\r\n    fn rotate(k: vec2<f32>, t: f32) -> vec2<f32> {\r\n        return vec2<f32>(cos(t) * k.x - sin(t) * k.y, sin(t) * k.x + cos(t) * k.y);\r\n    }   \r\n \r\n    fn map(p: vec3<f32>, s: f32) -> f32 {\r\n        var p_var = p;\r\n        var scale: f32 = 1.;\r\n        orb = vec4<f32>(1000.);\r\n    \r\n        for (var i: i32 = 0; i < 8; i = i + 1) {\r\n            p_var = -1. + 2. * fract(0.5 * p_var + 0.5);\r\n            let r2: f32 = dot(p_var, p_var);\r\n            orb = min(orb, vec4<f32>(abs(p_var), r2));\r\n            let k: f32 = s / r2;\r\n            p_var = p_var * (k);\r\n            scale = scale * (k);\r\n        }\r\n    \r\n        return 0.25 * abs(p_var.y) / scale;\r\n    } \r\n    \r\n    \r\n    fn calcNormal(pos: vec3<f32>, t: f32, s: f32) -> vec3<f32> {\r\n        let precis: f32 = 0.001 * t;\r\n        let e: vec2<f32> = vec2<f32>(1., -1.) * precis;\r\n        return normalize(e.xyy * map(pos + e.xyy, s) + e.yyx * map(pos + e.yyx, s) + e.yxy * map(pos + e.yxy, s) + e.xxx * map(pos + e.xxx, s));\r\n    } \r\n    \r\n    \r\n\r\n    fn trace(ro: vec3<f32>, rd: vec3<f32>, s: f32) -> f32 {\r\n        var maxd: f32 = 30.;\r\n        var t: f32 = 0.01;\r\n    \r\n        for (var i: i32 = 0; i < 512; i = i + 1) {\r\n            let precis: f32 = 0.001 * t;\r\n            let h: f32 = map(ro + rd * t, s);\r\n            if (h < precis || t > maxd) {\t\tbreak;\r\n     }\r\n            t = t + (h);\r\n        }\r\n    \r\n        if (t > maxd) { t = -1.; }\r\n        return t;\r\n    } \r\n    \r\n\r\n    fn render(ro: vec3<f32>, rd: vec3<f32>, anim: f32) -> vec3<f32> {\r\n        var col: vec3<f32> = vec3<f32>(0.);\r\n        let t: f32 = trace(ro, rd, anim);\r\n        if (t > 0.) {\r\n            let tra: vec4<f32> = orb;\r\n            let pos: vec3<f32> = ro + t * rd;\r\n            let nor: vec3<f32> = calcNormal(pos, t, anim);\r\n            let light1: vec3<f32> = vec3<f32>(0.577, 0.577, -0.577);\r\n            let light2: vec3<f32> = vec3<f32>(-0.707, 0., 0.707);\r\n            let key: f32 = clamp(dot(light1, nor), 0., 1.);\r\n            let bac: f32 = clamp(0.2 + 0.8 * dot(light2, nor), 0., 1.);\r\n            let amb: f32 = 0.7 + 0.3 * nor.y;\r\n            let ao: f32 = pow(clamp(tra.w * 2., 0., 1.), 1.2);\r\n            var brdf: vec3<f32> = 1. * vec3<f32>(0.4, 0.4, 0.4) * amb * ao;\r\n            brdf = brdf + (1. * vec3<f32>(1., 1., 1.) * key * ao);\r\n            brdf = brdf + (1. * vec3<f32>(0.4, 0.4, 0.4) * bac * ao);\r\n            var rgb: vec3<f32> = vec3<f32>(1.);\r\n            rgb = mix(rgb, vec3<f32>(1., 0.8, 0.2), clamp(6. * tra.y, 0., 1.));\r\n            rgb = mix(rgb, vec3<f32>(1., 0.55, 0.), pow(clamp(1. - 2. * tra.z, 0., 1.), 8.));\r\n            col = rgb * brdf * exp(-0.2 * t);\r\n        }\r\n        return sqrt(col);\r\n    } \r\n    \r\n    \r\n\r\n    \r\n    fn mainImage(pos: vec2<f32>) -> vec4<f32> {\r\n\r\n        /*\r\n        let x = pos.x * inner_width * 0.5;\r\n        let y = pos.y * inner_height * 0.5;\r\n        */\r\n\r\n        let fragCoord:vec2<f32> = vec2<f32>(pos.x * uniforms.resolution.x * 0.5,\r\n            pos.y * uniforms.resolution.y * 0.5\r\n            );\r\n\r\n        let uv: vec2<f32> = fragCoord.xy / uniforms.resolution.xy - 0.5;\r\n\r\n        let time: f32 = (uniforms.time * 0.25);\r\n        let anim: f32 = 1.1; // + 0.5 * smoothstep(-0.3, 0.3, cos(0.1 * uniforms.time));\r\n    \r\n        var tot: vec3<f32> = vec3<f32>(0.);\r\n\r\n        let ii: i32 = 1;\r\n        let jj: i32 = 1;\r\n        \r\n        let p: vec2<f32> = (2. * fragCoord.xy - uniforms.resolution.xy) / uniforms.resolution.y;\r\n\r\n        let ro: vec3<f32> = vec3<f32>(2.8 * cos(0.1 + 0.33 * time), 0.4 + 0.3 * cos(0.37 * time), 2.8 * cos(0.5 + 0.35 * time));\r\n        let ta: vec3<f32> = vec3<f32>(1.9 * cos(1.2 + 0.41 * time), 0.4 + 0.1 * cos(0.27 * time), 1.9 * cos(2. + 0.38 * time));\r\n        let roll: f32 = 0.2 * cos(0.1 * time);\r\n        let cw: vec3<f32> = normalize(ta - ro);\r\n        let cp: vec3<f32> = vec3<f32>(sin(roll), cos(roll), 0.);\r\n        let cu: vec3<f32> = normalize(cross(cw, cp));\r\n        let cv: vec3<f32> = normalize(cross(cu, cw));\r\n        let rd: vec3<f32> = normalize(p.x * cu + p.y * cv + 2. * cw);\r\n        tot = tot + render(ro, rd, anim);\r\n        return vec4<f32>(tot, 1.);\r\n       \r\n \r\n    } \r\n  \r\n    @fragment\r\n    fn main_fragment(in: VertexOutput) -> @location(0) vec4<f32> {      \r\n        return mainImage(in.uv);\r\n    }\r\n    \r\n\r\n\r\n    `\n};\n\n\n//# sourceURL=webpack://demolishedwebgpu/./example/shaders/wglsl/raymarchShader.js?");

/***/ }),

/***/ "./src/Geometry.js":
/*!*************************!*\
  !*** ./src/Geometry.js ***!
  \*************************/
/***/ ((__unused_webpack_module, exports) => {

eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Geometry = exports.DefaultIndicies = exports.VERTEXType = void 0;\nvar VERTEXType;\n(function (VERTEXType) {\n    VERTEXType[VERTEXType[\"xyz\"] = 3] = \"xyz\";\n    VERTEXType[VERTEXType[\"xyzw\"] = 4] = \"xyzw\";\n    VERTEXType[VERTEXType[\"xyzrgba\"] = 7] = \"xyzrgba\";\n    VERTEXType[VERTEXType[\"xyzwrgba\"] = 8] = \"xyzwrgba\";\n})(VERTEXType || (exports.VERTEXType = VERTEXType = {}));\nexports.DefaultIndicies = new Uint16Array([0, 1, 2, 3, 4, 5]);\n// let createBuffer = (arr: Float32Array | Uint16Array, usage: number) => {\n//     let desc = {\n//         size: (arr.byteLength + 3) & ~3,\n//         usage,\n//         mappedAtCreation: true\n//     };\n//     let buffer = this.device.createBuffer(desc);\n//     const writeArray =\n//         arr instanceof Uint16Array\n//             ? new Uint16Array(buffer.getMappedRange())\n//             : new Float32Array(buffer.getMappedRange());\n//     writeArray.set(arr);\n//     buffer.unmap();\n//     return buffer;\n//};\nclass Geometry {\n    createBuffer(arr, usage, vertexSize) {\n        let desc = {\n            size: (arr.byteLength + vertexSize) & ~vertexSize,\n            usage,\n            mappedAtCreation: true\n        };\n        let buffer = this.device.createBuffer(desc);\n        const writeArray = arr instanceof Uint16Array\n            ? new Uint16Array(buffer.getMappedRange())\n            : new Float32Array(buffer.getMappedRange());\n        writeArray.set(arr);\n        buffer.unmap();\n        return buffer;\n    }\n    constructor(device, model) {\n        this.device = device;\n        this.model = model;\n        this.vertexBuffer = this.createBuffer(model.vertices, GPUBufferUsage.VERTEX | GPUBufferUsage.COPY_DST, model.verticesType);\n        this.indexBuffer = this.createBuffer(model.indicies, GPUBufferUsage.INDEX, 3);\n        this.numOfVerticles = model.vertices.length / model.verticesType;\n    }\n    vertexBufferLayout(shaderLocation) {\n        const vertexBufferLayout = {\n            attributes: [{\n                    shaderLocation: shaderLocation,\n                    offset: 0,\n                    format: 'float32x2'\n                }],\n            arrayStride: 4 * this.model.verticesType,\n            stepMode: 'vertex'\n        };\n        return vertexBufferLayout;\n    }\n}\nexports.Geometry = Geometry;\n\n\n//# sourceURL=webpack://demolishedwebgpu/./src/Geometry.js?");

/***/ }),

/***/ "./src/ITexture.js":
/*!*************************!*\
  !*** ./src/ITexture.js ***!
  \*************************/
/***/ ((__unused_webpack_module, exports) => {

eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.TextureType = void 0;\nvar TextureType;\n(function (TextureType) {\n    TextureType[TextureType[\"image\"] = 0] = \"image\";\n    TextureType[TextureType[\"video\"] = 1] = \"video\";\n    TextureType[TextureType[\"canvas\"] = 2] = \"canvas\";\n    TextureType[TextureType[\"mediaStream\"] = 3] = \"mediaStream\";\n})(TextureType || (exports.TextureType = TextureType = {}));\n\n\n//# sourceURL=webpack://demolishedwebgpu/./src/ITexture.js?");

/***/ }),

/***/ "./src/Material.js":
/*!*************************!*\
  !*** ./src/Material.js ***!
  \*************************/
/***/ ((__unused_webpack_module, exports) => {

eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Material = exports.defaultWglslVertex = void 0;\nexports.defaultWglslVertex = `  \r\nstruct VertexInput {\r\n  @location(0) pos: vec2<f32>\r\n};  \r\nstruct VertexOutput {\r\n  @builtin(position) pos: vec4<f32>,\r\n  @location(0) uv: vec2<f32>\r\n};  \r\n\r\n@vertex\r\nfn main_vertex(input: VertexInput) -> VertexOutput {\r\n  var output: VertexOutput;\r\n  var pos: vec2<f32> = input.pos * 2.0 - 1.0;\r\n  output.pos = vec4<f32>(pos, 0.0, 1.0);\r\n  output.uv = input.pos;\r\n  return output;\r\n}`;\nclass Material {\n    constructor(device, shader) {\n        this.device = device;\n        this.shader = shader;\n        this.vertexShaderModule = this.device.createShaderModule({\n            code: shader.vertex,\n        });\n        this.fragmentShaderModule = this.device.createShaderModule({\n            code: shader.fragment\n        });\n    }\n    static createMaterialShader(spirvVert, spirvFrag, vertexEntryPoint, fragmentEntryPoint) {\n        const material = {\n            fragment: spirvFrag,\n            fragmentEntryPoint: fragmentEntryPoint,\n            vertex: spirvVert,\n            vertexEntryPoint: vertexEntryPoint\n        };\n        return material;\n    }\n}\nexports.Material = Material;\n\n\n//# sourceURL=webpack://demolishedwebgpu/./src/Material.js?");

/***/ }),

/***/ "./src/Mesh.js":
/*!*********************!*\
  !*** ./src/Mesh.js ***!
  \*********************/
/***/ ((__unused_webpack_module, exports) => {

eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Mesh = void 0;\nclass Mesh {\n    constructor(device, geometry, material, textures) {\n        this.device = device;\n        this.geometry = geometry;\n        this.material = material;\n        this.isEnables = true;\n        const layoutEntrys = [\n            {\n                binding: 0,\n                visibility: window.GPUShaderStage.FRAGMENT,\n                buffer: {\n                    type: \"uniform\"\n                }\n            }\n        ];\n        if (textures.length > 0) {\n            layoutEntrys.push({\n                binding: 1,\n                visibility: window.GPUShaderStage.FRAGMENT,\n                sampler: {\n                    type: \"filtering\"\n                }\n            });\n            for (let i = 0; i < textures.length; i++) { //  1-n texture bindings\n                if (textures[i].type === 0) {\n                    layoutEntrys.push({\n                        binding: 2 + i,\n                        visibility: window.GPUShaderStage.FRAGMENT,\n                        texture: {\n                            sampleType: \"float\"\n                        }\n                    });\n                }\n                else { //  external texture ( video )\n                    layoutEntrys.push({\n                        binding: 2 + i,\n                        visibility: window.GPUShaderStage.FRAGMENT,\n                        externalTexture: {}\n                    });\n                }\n            }\n        }\n        this.bindGroupLayout = this.device.createBindGroupLayout({\n            entries: layoutEntrys\n        });\n        this.pipelineLayout = this.device.createPipelineLayout({\n            bindGroupLayouts: [this.bindGroupLayout],\n        });\n    }\n    pipelineDescriptor() {\n        const pipelineDescriptor = {\n            vertex: {\n                module: this.material.vertexShaderModule,\n                entryPoint: this.material.shader.vertexEntryPoint || 'main_vertex',\n                buffers: [this.geometry.vertexBufferLayout(0)]\n            },\n            fragment: {\n                module: this.material.fragmentShaderModule,\n                entryPoint: this.material.shader.fragmentEntryPoint || 'main_fragment',\n                targets: [{\n                        format: 'bgra8unorm'\n                    }]\n            },\n            // depthStencil: {\n            //     format: 'depth32float',\n            //     depthWriteEnabled: true,\n            //     depthCompare: 'less'\n            // },\n            primitive: {\n                topology: 'triangle-list',\n            },\n            layout: this.pipelineLayout\n        };\n        return pipelineDescriptor;\n    }\n}\nexports.Mesh = Mesh;\n\n\n//# sourceURL=webpack://demolishedwebgpu/./src/Mesh.js?");

/***/ }),

/***/ "./src/Renderer.js":
/*!*************************!*\
  !*** ./src/Renderer.js ***!
  \*************************/
/***/ (function(__unused_webpack_module, exports) {

eval("\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Renderer = void 0;\nclass Renderer {\n    //uniforms: Float32Array;\n    constructor(canvas) {\n        //  this.textures = new Array<GPUTexture>();\n        this.canvas = canvas;\n    }\n    getDevice(config) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const device = yield this.initializeAPI();\n            if (device) {\n                this.context = this.canvas.getContext('webgpu');\n                const presentationFormat = navigator.gpu.getPreferredCanvasFormat();\n                const canvasConfig = config || {\n                    device: this.device,\n                    format: presentationFormat, // 'bgra8unorm',\n                    usage: GPUTextureUsage.RENDER_ATTACHMENT | GPUTextureUsage.COPY_SRC\n                };\n                this.context.configure(canvasConfig);\n                return device;\n            }\n        });\n    }\n    initializeAPI() {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                const entry = navigator.gpu;\n                if (!entry) {\n                    throw \"Cannot initalize WebGPU \";\n                }\n                this.adapter = yield entry.requestAdapter({\n                    powerPreference: \"high-performance\",\n                });\n                this.device = yield this.adapter.requestDevice();\n                this.queue = this.device.queue;\n            }\n            catch (e) {\n                throw \"Cannot initalize WebGPU \";\n            }\n            return this.device;\n        });\n    }\n    // updateCustomUniform(index:number,value:Float32Array){\n    //     this.scene.mesh.uniformBufferArray.set(value,index)\n    // }\n    //async initialize(geometry:Geometry,material:Material,texture?:Array<ITexture>,customUniforms?:Float32Array,samplers?:Array<GPUSamplerDescriptor>): Promise<void> {\n    addScene(scene) {\n        return __awaiter(this, void 0, void 0, function* () {\n            this.scene = scene;\n            // if(scene.customUniforms){ // extend uniforms if custom is passeds\n            //         uniforms.set(uniforms,4)\n            // }        \n            //  const mesh = scene.getMesh();\n            this.renderPipeline = this.device.createRenderPipeline(this.scene.getMesh().pipelineDescriptor());\n        });\n    }\n    draw(time) {\n        this.bindingGroup = this.device.createBindGroup({\n            layout: this.renderPipeline.getBindGroupLayout(0),\n            entries: this.scene.getBindingGroupEntrys(),\n        });\n        this.commandEncoder = this.device.createCommandEncoder();\n        const textureView = this.context.getCurrentTexture().createView();\n        const renderPassDescriptor = {\n            colorAttachments: [{\n                    loadOp: 'clear',\n                    storeOp: 'store',\n                    view: textureView\n                }]\n        };\n        this.scene.setUniforms([time], 3); // time\n        this.scene.updateUniformBuffer();\n        const passEncoder = this.commandEncoder.beginRenderPass(renderPassDescriptor);\n        passEncoder.setPipeline(this.renderPipeline);\n        passEncoder.setVertexBuffer(0, this.scene.getMesh().geometry.vertexBuffer);\n        passEncoder.setBindGroup(0, this.bindingGroup);\n        passEncoder.setIndexBuffer(this.scene.getMesh().geometry.indexBuffer, 'uint16');\n        passEncoder.drawIndexed(this.scene.getMesh().geometry.numOfVerticles, 1);\n        passEncoder.end();\n        this.device.queue.submit([this.commandEncoder.finish()]);\n    }\n    start(t, maxFps = 200) {\n        let startTime = null;\n        let frame = -1;\n        const renderLoop = (timestamp) => {\n            if (!startTime)\n                startTime = timestamp;\n            let segment = Math.floor((timestamp - startTime) / (1000 / maxFps));\n            if (segment > frame) {\n                frame = segment;\n                this.frame = frame;\n                if (!this.isPaused)\n                    this.draw(timestamp / 1000);\n            }\n            requestAnimationFrame(renderLoop);\n        };\n        renderLoop(t);\n    }\n    pause() {\n        this.isPaused = !this.isPaused;\n    }\n}\nexports.Renderer = Renderer;\n\n\n//# sourceURL=webpack://demolishedwebgpu/./src/Renderer.js?");

/***/ }),

/***/ "./src/Scene.js":
/*!**********************!*\
  !*** ./src/Scene.js ***!
  \**********************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

eval("\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Scene = exports.TextureCache = void 0;\nconst TextureLoader_1 = __webpack_require__(/*! ./TextureLoader */ \"./src/TextureLoader.js\");\nclass TextureCache {\n    constructor() {\n        this.entities = new Map();\n    }\n}\nexports.TextureCache = TextureCache;\nclass Scene {\n    getMesh(index = 0) {\n        return Array.from(this.meshes.values())[index];\n    }\n    setDimensions(width, height, dpr = 0) {\n        this.setUniforms([width, height, dpr], 0);\n    }\n    setUniforms(values, offset) {\n        this.uniformBufferArray.set(values, offset); // time \n    }\n    updateUniformBuffer() {\n        this.device.queue.writeBuffer(this.uniformBuffer, 0, this.uniformBufferArray.buffer, this.uniformBufferArray.byteOffset, this.uniformBufferArray.byteLength);\n    }\n    constructor(key, device, canvas) {\n        this.key = key;\n        this.device = device;\n        this.canvas = canvas;\n        this.meshes = new Map();\n        this.textures = new Array();\n        this.bindingGroupEntrys = new Array();\n        const dpr = window.devicePixelRatio || 1;\n        this.uniformBuffer = this.device.createBuffer({\n            size: 40,\n            usage: window.GPUBufferUsage.UNIFORM | window.GPUBufferUsage.COPY_DST,\n        });\n        this.uniformBufferArray = new Float32Array([this.canvas.width, this.canvas.height, 0, 1.0]);\n        console.log([this.canvas.width, this.canvas.height, dpr, 0]);\n        this.updateUniformBuffer();\n    }\n    getBindingGroupEntrys() {\n        const bindingGroupEntrys = [];\n        bindingGroupEntrys.push({\n            binding: 0,\n            resource: {\n                buffer: this.uniformBuffer\n            }\n        });\n        // todo: Cache the samples passed + default sampler ( linearSampler)\n        const sampler = this.device.createSampler({\n            addressModeU: 'repeat',\n            addressModeV: 'repeat',\n            magFilter: 'linear',\n            minFilter: 'nearest'\n        });\n        // add the a sampler\n        bindingGroupEntrys.push({\n            binding: 1,\n            resource: sampler\n        });\n        this.textures.forEach((t, i) => {\n            let entry;\n            if (t.type === 0) {\n                entry = {\n                    binding: i + 2,\n                    resource: t.data.createView()\n                };\n            }\n            else {\n                entry = {\n                    binding: i + 2,\n                    resource: this.device.importExternalTexture({ source: t.data }),\n                };\n            }\n            bindingGroupEntrys.push(entry);\n        });\n        return bindingGroupEntrys;\n    }\n    addAssets(textures, samplers) {\n        return __awaiter(this, void 0, void 0, function* () {\n            for (let i = 0; i < textures.length; i++) {\n                const texture = textures[i];\n                if (texture.type == 0) {\n                    this.textures.push({ type: 0, data: yield TextureLoader_1.TextureLoader.createImageTexture(this.device, texture) });\n                }\n                else\n                    this.textures.push({ type: 1, data: yield TextureLoader_1.TextureLoader.createVideoTextue(this.device, texture) });\n            }\n            this.bindingGroupEntrys = [{\n                    binding: 0,\n                    resource: {\n                        buffer: this.uniformBuffer\n                    }\n                }];\n            let textureBindingOffset = (samplers ? samplers.length : 0);\n            if (textures.length > 0 && !samplers) {\n                const sampler = this.device.createSampler({\n                    addressModeU: 'repeat',\n                    addressModeV: 'repeat',\n                    magFilter: 'linear',\n                    minFilter: 'nearest'\n                });\n                this.bindingGroupEntrys.push({\n                    binding: 1,\n                    resource: sampler\n                });\n                textureBindingOffset = 2;\n            }\n            else {\n                samplers.forEach((value, index) => {\n                    const sampler = this.device.createSampler(value);\n                    this.bindingGroupEntrys.push({\n                        binding: index + 1,\n                        resource: sampler\n                    });\n                    textureBindingOffset++;\n                });\n            }\n            this.textures.forEach((t, i) => {\n                let entry;\n                if (t.type === 0) {\n                    entry = {\n                        binding: i + textureBindingOffset,\n                        resource: t.data.createView()\n                    };\n                }\n                else {\n                    entry = {\n                        binding: i + textureBindingOffset,\n                        resource: this.device.importExternalTexture({ source: t.data })\n                    };\n                }\n                this.bindingGroupEntrys.push(entry);\n            });\n        });\n    }\n    addMesh(key, mesh) {\n        this.meshes.set(key, mesh);\n    }\n    removeMesh(key) {\n        return this.meshes.delete(key);\n    }\n}\nexports.Scene = Scene;\n\n\n//# sourceURL=webpack://demolishedwebgpu/./src/Scene.js?");

/***/ }),

/***/ "./src/TextureLoader.js":
/*!******************************!*\
  !*** ./src/TextureLoader.js ***!
  \******************************/
/***/ (function(__unused_webpack_module, exports) {

eval("\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.TextureLoader = void 0;\nclass TextureLoader {\n    constructor() {\n    }\n    /**\n     * Load and create an GPUTexture from an Image\n     *\n     * @static\n     * @param {GPUDevice} device\n     * @param {string} texture\n     * @return {*}  {Promise<GPUTexture>}\n     * @memberof TextureLoader\n     */\n    static createImageTexture(device, texture) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const image = new Image();\n            image.src = texture.source;\n            yield image.decode();\n            const imageBitmap = yield createImageBitmap(image);\n            const textureSize = { width: image.width, height: image.height };\n            const gpuTexture = device.createTexture({\n                label: texture.key,\n                size: textureSize,\n                dimension: '2d',\n                format: 'rgba8unorm',\n                usage: GPUTextureUsage.COPY_DST | GPUTextureUsage.RENDER_ATTACHMENT | GPUTextureUsage.TEXTURE_BINDING\n            });\n            device.queue.copyExternalImageToTexture({\n                source: imageBitmap\n            }, {\n                texture: gpuTexture,\n                mipLevel: 0\n            }, textureSize);\n            return gpuTexture;\n        });\n    }\n    static createVideoTextue(device, texture) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const video = document.createElement(\"video\");\n            video.loop = true;\n            video.autoplay = true;\n            video.muted = true;\n            if (texture.source instanceof MediaStream) {\n                video.srcObject = texture.source;\n            }\n            else\n                video.src = texture.source;\n            yield video.play();\n            return video;\n        });\n    }\n}\nexports.TextureLoader = TextureLoader;\n\n\n//# sourceURL=webpack://demolishedwebgpu/./src/TextureLoader.js?");

/***/ })

/******/ 	});
/************************************************************************/
/******/ 	// The module cache
/******/ 	var __webpack_module_cache__ = {};
/******/ 	
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/ 		// Check if module is in cache
/******/ 		var cachedModule = __webpack_module_cache__[moduleId];
/******/ 		if (cachedModule !== undefined) {
/******/ 			return cachedModule.exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = __webpack_module_cache__[moduleId] = {
/******/ 			// no module.id needed
/******/ 			// no module.loaded needed
/******/ 			exports: {}
/******/ 		};
/******/ 	
/******/ 		// Execute the module function
/******/ 		__webpack_modules__[moduleId].call(module.exports, module, module.exports, __webpack_require__);
/******/ 	
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/ 	
/************************************************************************/
/******/ 	
/******/ 	// startup
/******/ 	// Load entry module and return exports
/******/ 	// This entry module is referenced by other modules so it can't be inlined
/******/ 	var __webpack_exports__ = __webpack_require__("./example/Example.js");
/******/ 	
/******/ })()
;